{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import (roc_auc_score, precision_score, average_precision_score, recall_score,f1_score, accuracy_score,mean_squared_error,mean_absolute_error, roc_curve, auc, classification_report,auc,confusion_matrix,matthews_corrcoef)\n",
    "from sklearn import logger\n",
    "from sklearn.datasets import make_blobs,make_multilabel_classification\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import KernelCenterer,LabelEncoder, MinMaxScaler, Normalizer, QuantileTransformer, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import scipy as sp\n",
    "from scipy.linalg import svd,null_space\n",
    "import os\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering,SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.sparse import csr_matrix as sp\n",
    "import math\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.spatial.distance import cdist\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Import 3D plotting tools\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import roc_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hàm\tĐộ phức tạp tính toán\tBộ nhớ cần\n",
    "# preprocess_data_OC\tO(n⋅d²)\tO(n⋅d²)\n",
    "# clusterr\tO(n⋅d⋅k⋅iters)\tO(n⋅d)\n",
    "# nullspace\tO(d³)\tO(d²)\n",
    "# gram_schmidt\tO(d³)\tO(d²)\n",
    "# minimum_distance\tO(n⋅m⋅d)\tO(n⋅m)\n",
    "# distance_vector\tO(n⋅m⋅d)\tO(n⋅m)\n",
    "# calculate_NPD\tO(d³)\tO(d²)\n",
    "# learn\tO(n²⋅d)\tO(n²)\n",
    "\n",
    "\n",
    "\n",
    "alpha = 0.9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data_noise(train_data, test_data, noise_percentage=10):\n",
    "  \n",
    "    print(\"..............................Data Overview................................\")\n",
    "    print(\"Train Data Shape:\", train_data.shape)\n",
    "    print(\"Test Data Shape:\", test_data.shape)\n",
    "    \n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    X_train_total = train_data.iloc[:, :-1].to_numpy()\n",
    "    y_train_total = train_data.iloc[:, -1].to_numpy()\n",
    "\n",
    "    # Separate the samples with label 0\n",
    "    X_train = X_train_total[y_train_total == 0]\n",
    "    y_train = y_train_total[y_train_total == 0]\n",
    "\n",
    "    print(\"Train Data Labels [0]:\", np.unique(y_train))\n",
    "\n",
    "    # Calculate how many samples to add noise to based on the provided percentage\n",
    "    n_samples = X_train.shape[0]\n",
    "    noise_samples_count = int(n_samples * (noise_percentage / 100))\n",
    "\n",
    "    # Get the samples with label 1 (for generating noise)\n",
    "    X_train_noise = X_train_total[y_train_total == 1]\n",
    "    \n",
    "    # Randomly select noise_samples_count from X_train_noise\n",
    "    noisy_indices = np.random.choice(X_train_noise.shape[0], size=noise_samples_count, replace=False)\n",
    "    X_train_noise = X_train_noise[noisy_indices]\n",
    "    \n",
    "    # Add the noisy samples to the training set\n",
    "    X_train = np.vstack((X_train, X_train_noise))\n",
    "    y_train = np.concatenate((y_train, np.ones(X_train_noise.shape[0])))\n",
    "    print(y_train) \n",
    "    \n",
    "    # Prepare test data\n",
    "    X_test = test_data.iloc[:, :-1].to_numpy()\n",
    "    y_test = test_data.iloc[:, -1].to_numpy()\n",
    "\n",
    "    # Print the new size of training data\n",
    "    n_samples = X_train.shape[0]\n",
    "    n_features = X_train.shape[1]\n",
    "    print(\"Number of samples after adding noise:\", n_samples)\n",
    "    print(\"Number of features:\", n_features)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def cluster_kmeans(data, initial_k):\n",
    "    print(\"Starting K-Means clustering...\")\n",
    "\n",
    "    # Thực hiện K-Means clustering với số cụm initial_k\n",
    "    kmeans = KMeans(n_clusters=initial_k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(data)\n",
    "\n",
    "    # Gán nhãn cụm vào biến labels\n",
    "    labels = cluster_labels\n",
    "\n",
    "    # Sắp xếp dữ liệu theo nhãn cụm\n",
    "    sorted_indices = np.argsort(labels)\n",
    "    sorted_data = data[sorted_indices]\n",
    "    sorted_labels = labels[sorted_indices]\n",
    "\n",
    "    print(\"Final number of clusters:\", len(np.unique(sorted_labels)))\n",
    "    return sorted_data, sorted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nullspace(A):\n",
    "    _, s, vh = np.linalg.svd(A)\n",
    "    null_mask = np.isclose(s, 0)\n",
    "    null_space = vh[null_mask].T\n",
    "    return null_space\n",
    "\n",
    "\n",
    "def minimum_distance( A, B):\n",
    "        \"\"\"\n",
    "        Compute the minimum Euclidean distance from each point in A to all points in B.\n",
    "        \n",
    "        Parameters:\n",
    "        - A (ndarray): Set of points (N_A, d).\n",
    "        - B (ndarray): Set of points (N_B, d).\n",
    "        \n",
    "        Returns:\n",
    "        - min_distances (ndarray): Minimum distances from each point in A to the nearest point in B.\n",
    "        \"\"\"\n",
    "        A = np.asarray(A)\n",
    "        B = np.asarray(B)\n",
    "        \n",
    "        # Initialize an array for storing minimum distances\n",
    "        min_distances = np.empty(A.shape[0], dtype=np.float64)\n",
    "        \n",
    "        # Iterate over each point in A and calculate minimum distance to points in B\n",
    "        for i, a in enumerate(A):\n",
    "            distances = cdist([a], B, metric='euclidean')  # Compute all pairwise distances\n",
    "            min_distances[i] = np.min(distances)  # Store minimum distance\n",
    "        \n",
    "        return min_distances   \n",
    "\n",
    "def distance_vector(point_X, point_Y):\n",
    "    \"\"\"\n",
    "    Calculate pairwise Euclidean distance between two sets of points.\n",
    "    \n",
    "    Args:\n",
    "        point_X (ndarray): Array of shape (N_train, d) where N_train is the number of training samples and d is the number of features.\n",
    "        point_Y (ndarray): Array of shape (N_test, d) where N_test is the number of test samples and d is the number of features.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Distance matrix of shape (N_test, N_train) containing Euclidean distances between each pair of points.\n",
    "    \"\"\"\n",
    "    print( 'Complexity of calculate: ', point_X )\n",
    "    # Compute squared norms for each point\n",
    "    norm_X = np.sum(point_X**2, axis=1)  # (N_train,)\n",
    "    norm_Y = np.sum(point_Y**2, axis=1)  # (N_test,)\n",
    "    \n",
    "    # Compute the dot product between the two sets of points\n",
    "    dot_product = np.dot(point_Y, point_X.T)  # (N_test, N_train)\n",
    "    \n",
    "    # Apply Euclidean distance formula\n",
    "    distance = np.sqrt(abs(norm_Y[:, np.newaxis] + norm_X[np.newaxis, :] - 2 * dot_product))\n",
    "    return distance\n",
    "\n",
    "\n",
    "\n",
    "def calculate_NPD(X,y):\n",
    "    print(\"Begin calculating NPD --------------\")\n",
    "    X = X.T\n",
    "    print('shape of X', X.shape)\n",
    "    c = len(np.unique(y))  # Số lớp\n",
    "    d, N = X.shape  # Số đặc trưng và số mẫu\n",
    "    # Tính trung bình toàn cục và tạo ma trận P_t với zero-mean\n",
    "    mean_total = np.mean(X, axis=1, keepdims=True)\n",
    "    P_t = X - mean_total  # P_t là ma trận zero-mean có kích thước d x N\n",
    "    \n",
    "    # Tính P_w cho từng lớp\n",
    "    P_w = np.zeros_like(X)\n",
    "    for i in range(c):\n",
    "        class_mean = np.mean(X[:, y == i], axis=1, keepdims=True)\n",
    "        P_w[:, y == i] = X[:, y == i] - class_mean  # Tạo ma trận P_w có kích thước d x N\n",
    "        \n",
    "    # Tính ma trận phương sai S_w và S_t\n",
    "    S_w = np.dot(P_w, P_w.T) / N  # S_w là d x d\n",
    "    S_t = np.dot(P_t, P_t.T) / N  # S_t là d x d\n",
    "\n",
    "    print( \"rank sw st :\", np.linalg.matrix_rank(S_t) , np.linalg.matrix_rank(S_w)) \n",
    "    print( \"rank sw st :\", np.linalg.matrix_rank(P_t) , np.linalg.matrix_rank(P_w)) \n",
    "\n",
    "    \n",
    "    U, S, Vt = np.linalg.svd(P_t, full_matrices=False)\n",
    "    Q = U\n",
    "    B = nullspace(Q.T @ S_w @ Q)\n",
    "    W = Q @ B  # W có kích thước d x (c - 1)\n",
    "\n",
    "    # In kết quả\n",
    "    print(\"N =\", N,  \"  d =\", d, \"   c =\", c )\n",
    "    print(\"P_w : d x N =\", P_w.shape)  # d x N\n",
    "    print(\"P_t : d x N =\", P_t.shape)  # d x N\n",
    "    print(\"S_w : d x d =\", S_w.shape)  # d x d\n",
    "    print(\"S_t : d x d =\", S_t.shape)  # d x d\n",
    "    print(\"Q   : d x N =\", Q.shape)     # d x r\n",
    "    print(\"B   : N x L =\", B.shape)     # r x L\n",
    "    print(\"W   : d x L =\", W.shape)     # d x L\n",
    "    return W    \n",
    "\n",
    "    \n",
    "\n",
    "def BruteForce_Threshold(y_true, y_prob, minth=0.0, maxth=1.0, num_thresholds=1000):\n",
    "    \"\"\"\n",
    "    Finds the best classification threshold for a binary model using brute force search.\n",
    "\n",
    "    Args:\n",
    "        y_true (ndarray): True labels (0 or 1), shape (n_samples,).\n",
    "        y_prob (ndarray): Predicted probabilities for class 1, shape (n_samples,).\n",
    "        minth (float, optional): Minimum threshold value. Default is 0.0.\n",
    "        maxth (float, optional): Maximum threshold value. Default is 1.0.\n",
    "        num_thresholds (int, optional): Number of threshold values to search. Default is 1000.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing the best threshold for each evaluation metric.\n",
    "    \"\"\"\n",
    "    thresholds = np.linspace(minth, maxth, num_thresholds)  # Generate candidate thresholds\n",
    "\n",
    "    # Initialize best metrics\n",
    "    best_results = {\n",
    "        \"accuracy\": (0, 0),  # (best_threshold, best_score)\n",
    "        \"f1\": (0, 0),\n",
    "        \"mcc\": (0, 0),\n",
    "        \"auc_roc\": (0, 0),\n",
    "        \"auc_pr\": (0, 0)\n",
    "    }\n",
    "\n",
    "    return best_results \n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob[:,1] >= threshold).astype(int)\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        mcc = matthews_corrcoef(y_true, y_pred)\n",
    "        auc_roc = roc_auc_score(y_true, y_prob[:, 1])\n",
    "        auc_pr = average_precision_score(y_true, y_prob[:, 1])\n",
    "\n",
    "        # Update best threshold for each metric\n",
    "        if acc > best_results[\"accuracy\"][1]:\n",
    "            best_results[\"accuracy\"] = (threshold, acc)\n",
    "        if f1 > best_results[\"f1\"][1]:\n",
    "            best_results[\"f1\"] = (threshold, f1)\n",
    "        if mcc > best_results[\"mcc\"][1]:\n",
    "            best_results[\"mcc\"] = (threshold, mcc)\n",
    "        if auc_roc > best_results[\"auc_roc\"][1]:\n",
    "            best_results[\"auc_roc\"] = (threshold, auc_roc)\n",
    "        if auc_pr > best_results[\"auc_pr\"][1]:\n",
    "            best_results[\"auc_pr\"] = (threshold, auc_pr)\n",
    "\n",
    "    return best_results\n",
    "\n",
    "def learn( npd, X_train, y_train , X_test, t0):\n",
    "    '''\n",
    "    X_train n1, d \n",
    "\n",
    "    C: n * n * d \n",
    "    '''\n",
    "    t1 = time.time()\n",
    "    null_point_X = (sp(X_train).dot(sp(npd))).toarray()\n",
    "    null_point_X_test = (sp(X_test).dot(sp(npd))).toarray()  \n",
    "\n",
    "    train_score_tmp = distance_vector(null_point_X, null_point_X)\n",
    "    for i in range(len(train_score_tmp)):\n",
    "        train_score_tmp[i , i] = 1e9                                                      \n",
    "    train_score = np.amin(train_score_tmp, axis=1)\n",
    "    \n",
    "    y_score = minimum_distance(null_point_X_test, null_point_X)\n",
    "    y_proba = np.zeros((len(y_score), 2))\n",
    "    y_proba[:, 1] = np.minimum(y_score / np.max(train_score), 1)                         \n",
    "    y_proba[:, 0] = 1 - y_proba[:, 1]                                                     # Probability for class 0\n",
    "    \n",
    "    y_proba = np.nan_to_num(y_proba, nan=1.0)\n",
    "\n",
    "    y_predict = (y_proba[:, 1] > 0.5).astype(int) \n",
    "    \n",
    "    \n",
    "    \n",
    "    t2 = time.time()\n",
    "    print(\"...............................Timing Model................................\")\n",
    "    print(\"Time train:\", t1-t0)\n",
    "    print(\"Time test:\" , t2-t1)\n",
    "    return y_proba, y_predict, t1, t2  \n",
    "\n",
    "def Model_evaluating(y_true, y_predict, y_scores):\n",
    "    \"\"\"\n",
    "    Evaluate the model using various metrics such as AUC, AUCPR, Accuracy, MCC, F1-score, Precision, and Recall.\n",
    "    \n",
    "    Args:\n",
    "        y_true (ndarray): True labels.\n",
    "        y_predict (ndarray): Predicted labels.\n",
    "        y_scores (ndarray): Predicted probabilities for each class.\n",
    "        \n",
    "    Returns:\n",
    "        list: List of evaluation metrics.\n",
    "    \"\"\"\n",
    "    print(\"..............................Report Parameter...............................\")\n",
    "    \n",
    "    # Calculate MCC (Matthews Correlation Coefficient)\n",
    "    mcc = matthews_corrcoef(y_true, y_predict)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_true, y_predict)\n",
    "    \n",
    "    # Calculate PPV (Positive Predictive Value) or Precision\n",
    "    ppv = precision_score(y_true, y_predict)\n",
    "    \n",
    "    # Calculate TPR (True Positive Rate) or Recall/Sensitivity\n",
    "    tpr = recall_score(y_true, y_predict)\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    accuracy = accuracy_score(y_true, y_predict)\n",
    "    \n",
    "    # Calculate AUC (Area Under ROC Curve)\n",
    "    AUC = roc_auc_score(y_true, y_scores[:, 1])\n",
    "    \n",
    "    # Calculate AUCPR (Area Under Precision-Recall Curve)\n",
    "    AUCPR = average_precision_score(y_true, y_scores[:, 1])\n",
    "    \n",
    "    # Print out the evaluation metrics\n",
    "    print(\"AUCROC:\", AUC * 100)\n",
    "    print(\"AUCPR:\", AUCPR * 100)\n",
    "    print(\"Accuracy:\", accuracy * 100)\n",
    "    print(\"MCC:\", mcc)\n",
    "    print(\"F1 score:\", f1)\n",
    "    print(\"PPV (Precision):\", ppv)\n",
    "    print(\"TPR (Recall):\", tpr)\n",
    "\n",
    "    return [AUC * 100 if AUC else None, AUCPR * 100 if AUCPR else None,\n",
    "            accuracy * 100, mcc, f1, ppv, tpr]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = preprocess_data_OC(df2, df1)\n",
    "\n",
    "# X_total = np.vstack((X_train, X_test))\n",
    "# unique_rows = np.unique(X_total, axis=0)\n",
    "\n",
    "# print(\"Số dòng trong X_total:\", X_total.shape[0])   # Output: 5\n",
    "# print(\"Số dòng khác nhau:\", unique_rows.shape[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files from the GMM-nfst folder\n",
    "\n",
    "columns = [\"scaler\",\"nCluster\", 'noise_percentage', \"AUCROC\", \"AUCPR\", \"Accuracy\", \"MCC\", \"F1 Score\",\n",
    "           \"Precision\", \"Recall\", \"Time Train\", \"Time Test\"]\n",
    "# Now you can use df1 and df2 as DataFrames\n",
    "\n",
    "#CIC_IoT2023_1000.csv\n",
    "#N_BaIoT_1000.csv\n",
    "#BoT_IoT_1000.csv\n",
    "\n",
    "import cProfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# def plot_data_2D(X, labels, title=\"Interactive 3D PCA Plot\"):\n",
    "#     \"\"\" Vẽ dữ liệu với PCA và tạo đồ thị 3D có thể tương tác bằng Plotly \"\"\"\n",
    "\n",
    "#     # Ensure that n_components ≤ min(n_samples, n_features)\n",
    "#     n_components = min(3, X.shape[0], X.shape[1])\n",
    "#     if n_components < 3:\n",
    "#         print(f\"⚠️ Warning: Cannot plot 3D, because n_components={n_components}. Skipping...\")\n",
    "#         return\n",
    "    \n",
    "#     # Perform PCA\n",
    "#     pca = PCA(n_components=3)\n",
    "#     X_3D = pca.fit_transform(X)\n",
    "\n",
    "#     # Convert labels to a NumPy array\n",
    "#     labels = np.array(labels)\n",
    "\n",
    "#     # Create a DataFrame for better visualization\n",
    "#     import pandas as pd\n",
    "#     df = pd.DataFrame(X_3D, columns=['PCA 1', 'PCA 2', 'PCA 3'])\n",
    "#     df['Class'] = labels\n",
    "\n",
    "#     # Create an interactive 3D scatter plot\n",
    "#     fig = px.scatter_3d(df, x='PCA 1', y='PCA 2', z='PCA 3', \n",
    "#                          color=df['Class'].astype(str),  # Color by class\n",
    "#                          title=title, labels={'color': 'Class'},\n",
    "#                          opacity=0.8)\n",
    "\n",
    "#     fig.update_traces(marker=dict(size=5))  # Adjust marker size\n",
    "#     fig.show()\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def plot_data_2D(X, labels, title=\"Dữ liệu gốc trước khi biến đổi\"):\n",
    "    \"\"\" Vẽ dữ liệu với PCA để giảm xuống 2D \"\"\"\n",
    "    return 0 \n",
    "    pca = PCA(n_components=3)\n",
    "    X_2D = pca.fit_transform(X)  # Chuyển về dạng (100, 2)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    labels = np.array(labels)  \n",
    "    for i in np.unique(labels):\n",
    "        plt.scatter(X_2D[labels == i, 0], X_2D[labels == i, 1], label=f\"Class {i}\", alpha=0.7)\n",
    "\n",
    "    plt.xlabel(\"PCA 1\")\n",
    "    plt.ylabel(\"PCA 2\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def function(df1,df2, scaler, noise):\n",
    "\n",
    "    X_train0, y_train0, X_test, y_test = preprocess_data_noise( df1,df2, noise)\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"mean\") \n",
    "    X_train0[np.isinf(X_train0)] = np.nan  # Đổi vô hạn thành NaN\n",
    "    X_train0 = imputer.fit_transform(X_train0)\n",
    "    for ncluster in range(192, 194,1):\n",
    "        t0 = time.time()\n",
    "        X_train , y_train = cluster_kmeans( X_train0 , ncluster )\n",
    "        plot_data_2D(X_train, y_train, \"Du lieu sau clusterr\") \n",
    "        npd = calculate_NPD(X_train, y_train)\n",
    "        \n",
    "        y_proba, y_predict, t1, t2 = learn( npd , X_train, y_train, X_test, y_test)  #,y_predict\n",
    "        \n",
    "        # print(\"...............................Timing Model................................\")\n",
    "        # print(\"Time train:\", t1-t0)\n",
    "        # print(\"Time test:\" , t2-t1)\n",
    "        # print(\"...........................................................................\")\n",
    "        # print(y_predict)\n",
    "        v = Model_evaluating(y_test, y_predict, y_proba)\n",
    "        # best_thresholds = BruteForce_Threshold( y_test, y_proba, 0, 1)  \n",
    "        result = [scaler] + [ncluster] + [noise] + v + [t1-t0, t2-t1]\n",
    "        # for metric, (threshold, score) in best_thresholds.items():\n",
    "        #     result = result + [threshold, score ]  \n",
    "\n",
    "        result_df = pd.DataFrame([result], columns=columns)\n",
    "        result_df.to_csv(output_file, mode='a', header=not os.path.exists(output_file), index=False)\n",
    "        # result_df.to_csv(output_file, mode='a', header=(mark==0), index=False)\n",
    "        \n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "-------- data_ToNIoT ------------------------------\n",
      "--------------------------------------------------\n",
      "Processing dataset data_ToNIoT with QuantileTransformer scaler ...\n",
      "..............................Data Overview................................\n",
      "Train Data Shape: (34149, 29)\n",
      "Test Data Shape: (14636, 29)\n",
      "Train Data Labels [0]: [0]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Number of samples after adding noise: 3888\n",
      "Number of features: 28\n",
      "Starting K-Means clustering...\n",
      "Final number of clusters: 192\n",
      "Begin calculating NPD --------------\n",
      "shape of X (28, 3888)\n",
      "rank sw st : 23 18\n",
      "rank sw st : 24 18\n",
      "N = 3888   d = 28    c = 192\n",
      "P_w : d x N = (28, 3888)\n",
      "P_t : d x N = (28, 3888)\n",
      "S_w : d x d = (28, 28)\n",
      "S_t : d x d = (28, 28)\n",
      "Q   : d x N = (28, 28)\n",
      "B   : N x L = (28, 10)\n",
      "W   : d x L = (28, 10)\n",
      "Complexity of calculate:  [[-2.41665398e-16  4.45414667e-17  7.88642806e-21 ...  6.65922731e-32\n",
      "  -5.31096671e-46 -3.94450822e-16]\n",
      " [-2.41668819e-16  4.45718074e-17  7.88773774e-21 ...  6.65942334e-32\n",
      "  -5.31109404e-46 -3.94439946e-16]\n",
      " [-2.42348032e-16  5.05948039e-17  8.14772506e-21 ...  6.69833661e-32\n",
      "  -5.33636978e-46 -3.92280871e-16]\n",
      " ...\n",
      " [ 3.51822636e-17 -1.52878519e-17 -1.54704845e-20 ...  1.19322914e-31\n",
      "  -9.53139683e-46 -3.78885427e-16]\n",
      " [ 2.04685611e-17 -8.82479903e-18 -1.44116838e-20 ...  1.19519107e-31\n",
      "  -9.55620250e-46 -3.78959046e-16]\n",
      " [ 9.30171885e-17  7.08595408e-18 -6.96364121e-21 ...  4.00970995e-32\n",
      "  -2.84187919e-46 -1.08872582e-16]]\n",
      "...............................Timing Model................................\n",
      "Time train: [1.74719217e+09 1.74719217e+09 1.74719217e+09 ... 1.74719217e+09\n",
      " 1.74719217e+09 1.74719217e+09]\n",
      "Time test: 0.5590300559997559\n",
      "..............................Report Parameter...............................\n",
      "AUCROC: 93.35670814077369\n",
      "AUCPR: 98.45988494945948\n",
      "Accuracy: 11.91582399562722\n",
      "MCC: 0.011108262772620722\n",
      "F1 score: 0.0041711725629538085\n",
      "PPV (Precision): 0.9642857142857143\n",
      "TPR (Recall): 0.0020901068276823038\n",
      "Starting K-Means clustering...\n",
      "Final number of clusters: 193\n",
      "Begin calculating NPD --------------\n",
      "shape of X (28, 3888)\n",
      "rank sw st : 23 18\n",
      "rank sw st : 24 18\n",
      "N = 3888   d = 28    c = 193\n",
      "P_w : d x N = (28, 3888)\n",
      "P_t : d x N = (28, 3888)\n",
      "S_w : d x d = (28, 28)\n",
      "S_t : d x d = (28, 28)\n",
      "Q   : d x N = (28, 28)\n",
      "B   : N x L = (28, 10)\n",
      "W   : d x L = (28, 10)\n",
      "Complexity of calculate:  [[-9.72865578e-17  1.56696326e-16  1.54094333e-19 ...  2.33879857e-31\n",
      "   2.53926185e-46  5.20396242e-17]\n",
      " [-9.80654736e-17  1.56539826e-16  1.53546669e-19 ...  2.34525133e-31\n",
      "   2.55908379e-46  5.26091467e-17]\n",
      " [-9.81640936e-17  1.56520011e-16  1.53477329e-19 ...  2.34606832e-31\n",
      "   2.56159348e-46  5.26812550e-17]\n",
      " ...\n",
      " [ 2.67878486e-17  1.14111831e-16  1.28700000e-19 ...  3.41838049e-31\n",
      "   5.76089880e-46 -1.36480978e-16]\n",
      " [ 2.66068108e-17  1.14079545e-16  1.28571047e-19 ...  3.42145423e-31\n",
      "   5.76851001e-46 -1.36408403e-16]\n",
      " [ 2.70969290e-17  1.14173932e-16  1.28917318e-19 ...  3.41581999e-31\n",
      "   5.75303328e-46 -1.36706970e-16]]\n",
      "...............................Timing Model................................\n",
      "Time train: [1.74719218e+09 1.74719218e+09 1.74719218e+09 ... 1.74719218e+09\n",
      " 1.74719218e+09 1.74719218e+09]\n",
      "Time test: 0.5023074150085449\n",
      "..............................Report Parameter...............................\n",
      "AUCROC: 94.39872007203671\n",
      "AUCPR: 98.83141061167133\n",
      "Accuracy: 11.91582399562722\n",
      "MCC: 0.011108262772620722\n",
      "F1 score: 0.0041711725629538085\n",
      "PPV (Precision): 0.9642857142857143\n",
      "TPR (Recall): 0.0020901068276823038\n",
      "..............................Data Overview................................\n",
      "Train Data Shape: (34149, 29)\n",
      "Test Data Shape: (14636, 29)\n",
      "Train Data Labels [0]: [0]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "Number of samples after adding noise: 3926\n",
      "Number of features: 28\n",
      "Starting K-Means clustering...\n",
      "Final number of clusters: 192\n",
      "Begin calculating NPD --------------\n",
      "shape of X (28, 3926)\n",
      "rank sw st : 23 17\n",
      "rank sw st : 24 17\n",
      "N = 3926   d = 28    c = 192\n",
      "P_w : d x N = (28, 3926)\n",
      "P_t : d x N = (28, 3926)\n",
      "S_w : d x d = (28, 28)\n",
      "S_t : d x d = (28, 28)\n",
      "Q   : d x N = (28, 28)\n",
      "B   : N x L = (28, 11)\n",
      "W   : d x L = (28, 11)\n",
      "Complexity of calculate:  [[ 9.46784430e-04 -4.92081204e-03 -3.33883140e-03 ...  3.72525636e-18\n",
      "   0.00000000e+00 -4.20377296e-01]\n",
      " [ 9.46784430e-04 -4.92081204e-03 -3.33883140e-03 ...  3.72525636e-18\n",
      "   0.00000000e+00 -4.20377296e-01]\n",
      " [ 9.46784430e-04 -4.92081204e-03 -3.33883140e-03 ...  3.72525636e-18\n",
      "   0.00000000e+00 -4.20377296e-01]\n",
      " ...\n",
      " [ 9.46784430e-04 -4.92081204e-03 -3.33883140e-03 ...  3.72525636e-18\n",
      "   0.00000000e+00 -4.20377296e-01]\n",
      " [ 9.46784430e-04 -4.92081204e-03 -3.33883140e-03 ...  3.72525636e-18\n",
      "   0.00000000e+00 -4.20377296e-01]\n",
      " [ 9.46784430e-04 -4.92081204e-03 -3.33883140e-03 ...  3.72525636e-18\n",
      "   0.00000000e+00 -4.20377296e-01]]\n",
      "...............................Timing Model................................\n",
      "Time train: [1.74719218e+09 1.74719218e+09 1.74719218e+09 ... 1.74719218e+09\n",
      " 1.74719218e+09 1.74719218e+09]\n",
      "Time test: 0.5641162395477295\n",
      "..............................Report Parameter...............................\n",
      "AUCROC: 86.3617623188155\n",
      "AUCPR: 96.96922168416324\n",
      "Accuracy: 11.91582399562722\n",
      "MCC: 0.011108262772620722\n",
      "F1 score: 0.0041711725629538085\n",
      "PPV (Precision): 0.9642857142857143\n",
      "TPR (Recall): 0.0020901068276823038\n",
      "Starting K-Means clustering...\n",
      "Final number of clusters: 193\n",
      "Begin calculating NPD --------------\n",
      "shape of X (28, 3926)\n",
      "rank sw st : 23 18\n",
      "rank sw st : 24 18\n",
      "N = 3926   d = 28    c = 193\n",
      "P_w : d x N = (28, 3926)\n",
      "P_t : d x N = (28, 3926)\n",
      "S_w : d x d = (28, 28)\n",
      "S_t : d x d = (28, 28)\n",
      "Q   : d x N = (28, 28)\n",
      "B   : N x L = (28, 10)\n",
      "W   : d x L = (28, 10)\n",
      "Complexity of calculate:  [[-2.05961693e-16 -1.26287263e-16 -2.75954738e-19 ...  2.65411890e-31\n",
      "   0.00000000e+00  3.87093841e-16]\n",
      " [-2.07172282e-16 -1.26280890e-16 -2.76272133e-19 ...  2.67465314e-31\n",
      "   0.00000000e+00  3.91828226e-16]\n",
      " [-2.07616960e-16 -1.26233711e-16 -2.75654445e-19 ...  2.64424717e-31\n",
      "   0.00000000e+00  3.87797263e-16]\n",
      " ...\n",
      " [-1.50932393e-16 -1.26447152e-16 -2.89214511e-19 ...  2.80409869e-31\n",
      "   0.00000000e+00  3.62146315e-16]\n",
      " [-1.71618668e-16 -1.26233016e-16 -2.86173183e-19 ...  2.65954516e-31\n",
      "   0.00000000e+00  3.66409098e-16]\n",
      " [-1.72453921e-16 -1.26358572e-16 -2.86543814e-19 ...  2.66045280e-31\n",
      "   0.00000000e+00  3.67407541e-16]]\n",
      "...............................Timing Model................................\n",
      "Time train: [1.74719218e+09 1.74719218e+09 1.74719218e+09 ... 1.74719218e+09\n",
      " 1.74719218e+09 1.74719218e+09]\n",
      "Time test: 0.5265889167785645\n",
      "..............................Report Parameter...............................\n",
      "AUCROC: 85.92175666661439\n",
      "AUCPR: 96.9731288639635\n",
      "Accuracy: 11.91582399562722\n",
      "MCC: 0.011108262772620722\n",
      "F1 score: 0.0041711725629538085\n",
      "PPV (Precision): 0.9642857142857143\n",
      "TPR (Recall): 0.0020901068276823038\n",
      "..............................Data Overview................................\n",
      "Train Data Shape: (34149, 29)\n",
      "Test Data Shape: (14636, 29)\n",
      "Train Data Labels [0]: [0]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "Number of samples after adding noise: 4004\n",
      "Number of features: 28\n",
      "Starting K-Means clustering...\n",
      "Final number of clusters: 192\n",
      "Begin calculating NPD --------------\n",
      "shape of X (28, 4004)\n",
      "rank sw st : 24 18\n",
      "rank sw st : 25 18\n",
      "N = 4004   d = 28    c = 192\n",
      "P_w : d x N = (28, 4004)\n",
      "P_t : d x N = (28, 4004)\n",
      "S_w : d x d = (28, 28)\n",
      "S_t : d x d = (28, 28)\n",
      "Q   : d x N = (28, 28)\n",
      "B   : N x L = (28, 10)\n",
      "W   : d x L = (28, 10)\n",
      "Complexity of calculate:  [[ 7.66919409e-17  3.77880798e-17  5.01999258e-20 ...  6.90607434e-32\n",
      "   4.32576616e-46 -8.96119101e-17]\n",
      " [ 7.61401742e-17  3.78919284e-17  5.04199497e-20 ...  6.96917682e-32\n",
      "   4.35930756e-46 -8.85985096e-17]\n",
      " [ 7.56316105e-17  3.79876457e-17  5.06227460e-20 ...  7.02733843e-32\n",
      "   4.39022268e-46 -8.76644577e-17]\n",
      " ...\n",
      " [-4.81466373e-15 -1.08084489e-15 -1.05379037e-18 ... -2.88711361e-30\n",
      "  -8.24594015e-45 -4.85100626e-15]\n",
      " [-4.81163955e-15 -1.07739861e-15 -1.05372923e-18 ... -2.89424112e-30\n",
      "  -8.30404719e-45 -4.84493565e-15]\n",
      " [-4.82178351e-15 -1.07592364e-15 -1.05167878e-18 ... -2.89862615e-30\n",
      "  -8.32537262e-45 -4.85784441e-15]]\n",
      "...............................Timing Model................................\n",
      "Time train: [1.74719218e+09 1.74719218e+09 1.74719218e+09 ... 1.74719218e+09\n",
      " 1.74719218e+09 1.74719218e+09]\n",
      "Time test: 0.5410130023956299\n",
      "..............................Report Parameter...............................\n",
      "AUCROC: 81.99804362828775\n",
      "AUCPR: 95.92986777974451\n",
      "Accuracy: 11.881661656190216\n",
      "MCC: 0.009109040509809442\n",
      "F1 score: 0.003400046364268603\n",
      "PPV (Precision): 0.9565217391304348\n",
      "TPR (Recall): 0.0017030500077411363\n",
      "Starting K-Means clustering...\n",
      "Final number of clusters: 193\n",
      "Begin calculating NPD --------------\n",
      "shape of X (28, 4004)\n",
      "rank sw st : 24 18\n",
      "rank sw st : 25 18\n",
      "N = 4004   d = 28    c = 193\n",
      "P_w : d x N = (28, 4004)\n",
      "P_t : d x N = (28, 4004)\n",
      "S_w : d x d = (28, 28)\n",
      "S_t : d x d = (28, 28)\n",
      "Q   : d x N = (28, 28)\n",
      "B   : N x L = (28, 10)\n",
      "W   : d x L = (28, 10)\n",
      "Complexity of calculate:  [[ 1.08276478e-16 -7.28068424e-17 -8.07666375e-20 ... -2.85537731e-31\n",
      "  -2.55105071e-47 -1.56373139e-16]\n",
      " [ 1.07149975e-16 -7.60873262e-17 -8.75620796e-20 ... -2.92984094e-31\n",
      "  -2.68773566e-47 -1.65093778e-16]\n",
      " [ 1.07314589e-16 -7.62767455e-17 -8.76441973e-20 ... -2.93200433e-31\n",
      "  -2.69810723e-47 -1.65088702e-16]\n",
      " ...\n",
      " [-1.99040936e-15 -6.54347552e-16 -7.34471366e-19 ... -9.96458780e-31\n",
      "  -7.25249177e-47 -1.77155298e-15]\n",
      " [-2.02046969e-15 -6.50741786e-16 -7.41086954e-19 ... -9.81718797e-31\n",
      "  -6.84579241e-47 -1.77837324e-15]\n",
      " [-1.99451568e-15 -6.52613042e-16 -7.33036256e-19 ... -9.91161680e-31\n",
      "  -7.09020594e-47 -1.76933724e-15]]\n",
      "...............................Timing Model................................\n",
      "Time train: [1.74719219e+09 1.74719219e+09 1.74719219e+09 ... 1.74719219e+09\n",
      " 1.74719219e+09 1.74719219e+09]\n",
      "Time test: 0.5344738960266113\n",
      "..............................Report Parameter...............................\n",
      "AUCROC: 80.5661541836111\n",
      "AUCPR: 95.91962823274751\n",
      "Accuracy: 11.881661656190216\n",
      "MCC: 0.009109040509809442\n",
      "F1 score: 0.003400046364268603\n",
      "PPV (Precision): 0.9565217391304348\n",
      "TPR (Recall): 0.0017030500077411363\n",
      "..............................Data Overview................................\n",
      "Train Data Shape: (34149, 29)\n",
      "Test Data Shape: (14636, 29)\n",
      "Train Data Labels [0]: [0]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n",
      "Number of samples after adding noise: 4082\n",
      "Number of features: 28\n",
      "Starting K-Means clustering...\n",
      "Final number of clusters: 192\n",
      "Begin calculating NPD --------------\n",
      "shape of X (28, 4082)\n",
      "rank sw st : 23 18\n",
      "rank sw st : 24 18\n",
      "N = 4082   d = 28    c = 192\n",
      "P_w : d x N = (28, 4082)\n",
      "P_t : d x N = (28, 4082)\n",
      "S_w : d x d = (28, 28)\n",
      "S_t : d x d = (28, 28)\n",
      "Q   : d x N = (28, 28)\n",
      "B   : N x L = (28, 10)\n",
      "W   : d x L = (28, 10)\n",
      "Complexity of calculate:  [[-3.33353323e-18 -6.57974784e-18 -4.83685925e-21 ... -3.82491583e-33\n",
      "   4.95688557e-48 -1.93540479e-17]\n",
      " [-3.28892975e-17 -1.55971054e-17 -1.98773290e-21 ...  8.79931741e-33\n",
      "   8.49006295e-48 -4.89972882e-17]\n",
      " [-1.30663635e-17 -1.18076350e-17 -5.50868170e-21 ... -1.07246737e-33\n",
      "   7.71363164e-48 -3.46753694e-17]\n",
      " ...\n",
      " [-6.29290789e-13 -1.86895827e-13  7.15021297e-17 ...  2.52189787e-28\n",
      "  -9.62699256e-44 -5.11887447e-13]\n",
      " [-6.29339255e-13 -1.86912930e-13  7.15043027e-17 ...  2.52220891e-28\n",
      "  -9.62771081e-44 -5.11933129e-13]\n",
      " [ 4.69156179e-14  5.14903630e-14  1.23780018e-17 ... -3.24267033e-29\n",
      "   6.92885806e-45  1.67213659e-13]]\n",
      "...............................Timing Model................................\n",
      "Time train: [1.74719219e+09 1.74719219e+09 1.74719219e+09 ... 1.74719219e+09\n",
      " 1.74719219e+09 1.74719219e+09]\n",
      "Time test: 0.5407688617706299\n",
      "..............................Report Parameter...............................\n",
      "AUCROC: 79.6316304996088\n",
      "AUCPR: 95.59352566368008\n",
      "Accuracy: 11.91582399562722\n",
      "MCC: 0.011108262772620722\n",
      "F1 score: 0.0041711725629538085\n",
      "PPV (Precision): 0.9642857142857143\n",
      "TPR (Recall): 0.0020901068276823038\n",
      "Starting K-Means clustering...\n",
      "Final number of clusters: 193\n",
      "Begin calculating NPD --------------\n",
      "shape of X (28, 4082)\n",
      "rank sw st : 23 18\n",
      "rank sw st : 24 18\n",
      "N = 4082   d = 28    c = 193\n",
      "P_w : d x N = (28, 4082)\n",
      "P_t : d x N = (28, 4082)\n",
      "S_w : d x d = (28, 28)\n",
      "S_t : d x d = (28, 28)\n",
      "Q   : d x N = (28, 28)\n",
      "B   : N x L = (28, 10)\n",
      "W   : d x L = (28, 10)\n",
      "Complexity of calculate:  [[-4.59193628e-17 -1.37473187e-16  6.28574587e-19 ... -7.78326383e-32\n",
      "   1.19694660e-46 -3.32286717e-16]\n",
      " [-4.34739439e-17 -1.36980827e-16  6.26150866e-19 ... -7.80658076e-32\n",
      "   1.20153261e-46 -3.28995388e-16]\n",
      " [-4.31333122e-17 -1.36912245e-16  6.25813257e-19 ... -7.80982867e-32\n",
      "   1.20217142e-46 -3.28536926e-16]\n",
      " ...\n",
      " [ 2.90974083e-16  4.67514427e-17 -1.97415132e-19 ... -3.13212235e-32\n",
      "   2.15212120e-47  3.44611971e-16]\n",
      " [ 2.85032333e-16  4.51491919e-17 -1.90713267e-19 ... -3.51939137e-32\n",
      "   2.67354519e-47  3.40038541e-16]\n",
      " [-2.78883232e-16 -1.63811553e-16  7.19629878e-19 ...  3.47120139e-33\n",
      "   6.32088654e-47 -5.26323633e-16]]\n",
      "...............................Timing Model................................\n",
      "Time train: [1.74719219e+09 1.74719219e+09 1.74719219e+09 ... 1.74719219e+09\n",
      " 1.74719219e+09 1.74719219e+09]\n",
      "Time test: 0.540675163269043\n",
      "..............................Report Parameter...............................\n",
      "AUCROC: 80.1841146834488\n",
      "AUCPR: 95.52847968527873\n",
      "Accuracy: 11.91582399562722\n",
      "MCC: 0.011108262772620722\n",
      "F1 score: 0.0041711725629538085\n",
      "PPV (Precision): 0.9642857142857143\n",
      "TPR (Recall): 0.0020901068276823038\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cProfile\n",
    "import pstats    \n",
    "\n",
    "# dataset_prefixes =  ['N_BaIoT_dataloader.csv']\n",
    "#dataset_prefixes =  [ 'data_N_BaIoT'] #,'data_N_BaIoT', 'data_BoTIoT'] 'data_CICIoT2023.csv'\n",
    "dataset_prefixes =  ['data_ToNIoT'] #'data_ToNIoT'\n",
    "\n",
    "#  'data_N_BaIoT.csv',  \n",
    "# scaler_names = ['MinMaxScaler']\n",
    "scaler_names = ['QuantileTransformer']\n",
    "#  \n",
    "# scaler_names = ['QuantileTransformer', 'StandardScaler','QuantileTransformer','MinMaxScaler']\n",
    "\n",
    "    # Iterate through dataset prefixes and process each dataset pair\n",
    "\n",
    "\n",
    "\n",
    "for prefix in dataset_prefixes:\n",
    "    \n",
    "    print(\"-\"*50)\n",
    "    print(\"--------\", prefix , \"-\"*30)\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    base_output_file = f\"Structure_Result/Kmean_73_old_{prefix}.csv0.csv\" \n",
    "    output_file = base_output_file + \"0.csv\"\n",
    "\n",
    "    # Increment the filename if it already exists\n",
    "    counter = 0\n",
    "    while os.path.exists(output_file):\n",
    "        counter += 1\n",
    "        output_file = f\"{base_output_file}{counter}.csv\"\n",
    "\n",
    "        \n",
    "    for scaler in scaler_names: \n",
    "        print(f\"Processing dataset {prefix} with {scaler} scaler ...\")\n",
    "        \n",
    "        # Construct file paths for train and test datasets with 'Train_' and 'Test_' prefixes\n",
    "        train_file = f'Datascaled/NoiseOCData/Train_{scaler}_{prefix}.csv'\n",
    "        test_file = f'Datascaled/NoiseOCData/Test_{scaler}_{prefix}.csv'\n",
    "        \n",
    "        # Load the CSV files\n",
    "        df_train = pd.read_csv(train_file)\n",
    "        df_test = pd.read_csv(test_file)\n",
    "\n",
    "        df_train = df_train.dropna() \n",
    "        df_test = df_test.dropna() \n",
    "            \n",
    "            # Nối lại thành 1 DataFrame\n",
    "        df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
    "            \n",
    "            # Chia theo tỉ lệ 70% train, 30% test\n",
    "        df_train_new, df_test_new = train_test_split(df_full, test_size=0.3, random_state=42)\n",
    "        for noise in [0, 1, 3, 5]:\n",
    "        # for noise in range (0, 6): \n",
    "            \n",
    "            # log_file = f'Results/OURMODEL/SCALERS/{prefix}_modellog.txt'\n",
    "            # with open(log_file, \"w\") as f:\n",
    "            #     profiler = cProfile.Profile()\n",
    "            #     profiler.enable()\n",
    "                \n",
    "            function(df_train_new, df_test_new, scaler, noise)  # Chạy hàm cần profile\n",
    "            \n",
    "                # profiler.disable()\n",
    "                # stats = pstats.Stats(profiler, stream=f)\n",
    "                # stats.sort_stats(\"cumulative\").print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
