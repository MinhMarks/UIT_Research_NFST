{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8a18763-100b-465d-b191-de03da098cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 0 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      "*** 1 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      "*** 3 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      "*** 5 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Đường dẫn các file dữ liệu\n",
    "baseline_file = \"~/GMM-nfst/Results/Baseline_noise73.csv\"\n",
    "model_files = {\n",
    "    # \"data_BoTIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_BoTIoT.csv0.csv\",\n",
    "    # \"data_CICIoT2023.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_CICIoT2023.csv0.csv\",\n",
    "    # \"data_N_BaIoT.csv\" : \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_N_BaIoT.csv0.csv\",\n",
    "    \"data_ToNIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_ToNIoT.csv0.csv\"\n",
    "}\n",
    "\n",
    "scaler_names = ['MinMaxScaler', 'Normalizer', 'StandardScaler', 'QuantileTransformer', 'RobustScaler']\n",
    "metric_names = ['AUCROC'] # , 'AUCPR', 'Accuracy', 'MCC', 'F1 Score']   \n",
    "# Đọc dữ liệu baseline\n",
    "baseline_df = pd.read_csv(os.path.expanduser(baseline_file))\n",
    "\n",
    "# Lặp qua từng mức noise\n",
    "for noise in [0, 1, 3, 5]: \n",
    "    baseline_noise = baseline_df[baseline_df[\"noise_percentage\"] == noise]\n",
    "    baseline_noise = baseline_noise[baseline_noise['Model'] != 'LUNAR']\n",
    "\n",
    "    for dataset, model_file_path in model_files.items():\n",
    "        \n",
    "\n",
    "        # Đọc dữ liệu mô hình của bạn\n",
    "        model_df = pd.read_csv(os.path.expanduser(model_file_path))\n",
    "        model_noise = model_df[model_df[\"noise_percentage\"] == noise]\n",
    "\n",
    "        for metric in metric_names: \n",
    "\n",
    "            best_metric = -1\n",
    "        \n",
    "            # Tìm mô hình của bạn có AUCROC cao nhất\n",
    "            for scaler in scaler_names:\n",
    "                model_scaler = model_noise[model_noise[\"scaler\"] == scaler]\n",
    "                for _, row in model_scaler.iterrows():\n",
    "                    if row[metric] > best_metric:\n",
    "                        best_metric = row[metric]\n",
    "    \n",
    "            best_model_row = None\n",
    "            \n",
    "            # if best_model_row is None:\n",
    "            #     best_model_row = pd.Series({'Model': 'ourmodel', dataset: 0})\n",
    "            # else:\n",
    "\n",
    "            col_name = f\"{dataset}_{metric}\"\n",
    "            best_model_row = pd.Series({'Model': 'ourmodel', col_name: best_metric})\n",
    "\n",
    "            \n",
    "            # Lọc baseline theo dataset\n",
    "            dataset_baseline = baseline_noise[baseline_noise[\"Dataset\"] == dataset]\n",
    "            selected_columns = dataset_baseline[['Model', metric, 'scaled']]\n",
    "\n",
    "            print( f'*** {noise} - {scaler} - {dataset} - So luong model khac nhau : ' , selected_columns['Model'].nunique() ) \n",
    "            \n",
    "            # Tìm baseline model có AUCROC < best_model AUCROC\n",
    "            sorted_baseline = selected_columns.sort_values(by=metric, ascending=False)\n",
    "\n",
    "             \n",
    "            grouped = sorted_baseline.groupby(\"Model\")\n",
    "\n",
    "            baseline_rows = []\n",
    "            for model_name, group in grouped:\n",
    "                filtered = group[group[metric] < best_metric]\n",
    "             \n",
    "                if not filtered.empty:\n",
    "                    best_row = filtered.loc[filtered[metric].idxmax()]\n",
    "                    baseline_rows.append({\n",
    "                        \"Model\": model_name,\n",
    "                        col_name: best_row[metric]\n",
    "                    })\n",
    "                else:\n",
    "                    baseline_rows.append({\n",
    "                        \"Model\": model_name,\n",
    "                        col_name: best_metric * 1.05  # gán 100 nếu không có model baseline nào thấp hơn\n",
    "                    })\n",
    "                    \n",
    "            # Tạo dataframe kết quả\n",
    "\n",
    "            report_df = pd.DataFrame([best_model_row.to_dict()] + baseline_rows )\n",
    "                # report_df = pd.DataFrame(report_rows)\n",
    "    \n",
    "            # Ghi kết quả ra file\n",
    "            report_path = f\"Results/final/{metric}_report_noise_{noise}.csv\"\n",
    "            if os.path.exists(report_path):\n",
    "                old_df = pd.read_csv(report_path)\n",
    "                merged_df = pd.merge(old_df, report_df, on='Model', how='inner')\n",
    "                merged_df.to_csv(report_path, index=False)\n",
    "            else:\n",
    "                report_df.to_csv(report_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d62217c9-e3b1-429a-8c4f-9d811dbe1af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 0 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 0 - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 0 - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 0 - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 0 - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 0 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      "*** 1 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 1 - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 1 - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 1 - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 1 - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 1 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      "*** 3 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 3 - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 3 - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 3 - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 3 - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 3 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      "*** 5 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 5 - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 5 - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 5 - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 5 - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  16\n",
      " 5 - RobustScaler - data_ToNIoT.csv - So luong model khac nhau :  16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Đường dẫn các file dữ liệu\n",
    "# baseline_file = \"~/GMM-nfst/Results/Baseline_noise73.csv\"\n",
    "# model_files = {\n",
    "#     # \"data_BoTIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_BoTIoT.csv0.csv\",\n",
    "#     # \"data_CICIoT2023.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_CICIoT2023.csv0.csv\",\n",
    "#     # \"data_N_BaIoT.csv\" : \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_N_BaIoT.csv0.csv\",\n",
    "#     \"data_ToNIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_ToNIoT.csv0.csv\"\n",
    "# }\n",
    "\n",
    "# scaler_names = ['MinMaxScaler', 'Normalizer', 'StandardScaler', 'QuantileTransformer', 'RobustScaler']\n",
    "# metric_names = ['AUCROC'] # , 'AUCPR', 'Accuracy', 'MCC', 'F1 Score']   \n",
    "# # Đọc dữ liệu baseline\n",
    "# baseline_df = pd.read_csv(os.path.expanduser(baseline_file))\n",
    "\n",
    "# # Lặp qua từng mức noise\n",
    "# for noise in [0, 1, 3, 5]: \n",
    "#     baseline_noise = baseline_df[baseline_df[\"noise_percentage\"] == noise]\n",
    "#     baseline_noise = baseline_noise[baseline_noise['Model'] != 'LUNAR']\n",
    "\n",
    "#     for dataset, model_file_path in model_files.items():\n",
    "        \n",
    "\n",
    "#         # Đọc dữ liệu mô hình của bạn\n",
    "#         model_df = pd.read_csv(os.path.expanduser(model_file_path))\n",
    "#         model_noise = model_df[model_df[\"noise_percentage\"] == noise]\n",
    "\n",
    "#         for metric in metric_names: \n",
    "\n",
    "#             best_metric = -1\n",
    "        \n",
    "#             # Tìm mô hình của bạn có AUCROC cao nhất\n",
    "#             for scaler in scaler_names:\n",
    "#                 model_scaler = model_noise[model_noise[\"scaler\"] == scaler]\n",
    "#                 for _, row in model_scaler.iterrows():\n",
    "#                     if row[metric] > best_metric:\n",
    "#                         best_metric = row[metric]\n",
    "    \n",
    "#             best_model_row = None\n",
    "            \n",
    "#             # if best_model_row is None:\n",
    "#             #     best_model_row = pd.Series({'Model': 'ourmodel', dataset: 0})\n",
    "#             # else:\n",
    "\n",
    "#             col_name = f\"{dataset}_{metric}\"\n",
    "#             best_model_row = pd.Series({'Model': 'ourmodel', col_name: best_metric})\n",
    "\n",
    "            \n",
    "#             # Lọc baseline theo dataset\n",
    "#             dataset_baseline = baseline_noise[baseline_noise[\"Dataset\"] == dataset]\n",
    "#             selected_columns = dataset_baseline[['Model', metric, 'scaled']]\n",
    "\n",
    "#             print( f'*** {noise} - {scaler} - {dataset} - So luong model khac nhau : ' , selected_columns['Model'].nunique() ) \n",
    "            \n",
    "#             # Tìm baseline model có AUCROC < best_model AUCROC\n",
    "#             sorted_baseline = selected_columns.sort_values(by=metric, ascending=False)\n",
    "\n",
    "#             best_baseline_rows = [] \n",
    "#             best_loss = 1000  \n",
    "            \n",
    "#                 scaler_baseline = sorted_baseline[sorted_baseline[\"scaled\"] == scaler] \n",
    "                \n",
    "#                 grouped = scaler_baseline.groupby(\"Model\")\n",
    "    \n",
    "#                 print( f' {noise} - {scaler} - {dataset} - So luong model khac nhau : ' ,  scaler_baseline['Model'].nunique() ) \n",
    "#                 baseline_rows = []\n",
    "#                 for model_name, group in grouped:\n",
    "#                     filtered = group[group[metric] < best_metric]\n",
    "                 \n",
    "#                     if not filtered.empty:\n",
    "#                         best_row = filtered.loc[filtered[metric].idxmax()]\n",
    "#                         baseline_rows.append({\n",
    "#                             \"Model\": model_name,\n",
    "#                             col_name: best_row[metric]\n",
    "#                         })\n",
    "#                     else:\n",
    "#                         baseline_rows.append({\n",
    "#                             \"Model\": model_name,\n",
    "#                             col_name: best_metric * 1.05  # gán 100 nếu không có model baseline nào thấp hơn\n",
    "#                         })\n",
    "                        \n",
    "#                 # Tạo dataframe kết quả\n",
    "    \n",
    "#                 size_tmp = sum(1 for row in baseline_rows if row[col_name] > best_metric)\n",
    "                \n",
    "#                 baseline_rows.append({'Model': 'Thua bao nhieu', col_name: size_tmp})\n",
    "\n",
    "#                 if ( size_tmp < best_loss ): \n",
    "#                     best_loss = size_tmp \n",
    "#                     best_baseline_rows = baseline_rows.copy() \n",
    "            \n",
    "#             report_df = pd.DataFrame([best_model_row.to_dict()] + best_baseline_rows )\n",
    "#                 # report_df = pd.DataFrame(report_rows)\n",
    "    \n",
    "#             # Ghi kết quả ra file\n",
    "#             report_path = f\"Results/final/{metric}_report_noise_{noise}.csv\"\n",
    "#             if os.path.exists(report_path):\n",
    "#                 old_df = pd.read_csv(report_path)\n",
    "#                 merged_df = pd.merge(old_df, report_df, on='Model', how='inner')\n",
    "#                 merged_df.to_csv(report_path, index=False)\n",
    "#             else:\n",
    "#                 report_df.to_csv(report_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed26595-dc8e-4a75-8816-d3826d34da00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "        # report_df = pd.concat([best_model_df, sorted_baseline], ignore_index=True).fillna(0) \n",
    "        # # report_df.rename(columns={'AUCPR': dataset }, inplace=True)\n",
    "        # report_df.columns.values[1] = dataset \n",
    "        # report_path = f\"Results/final_report_noise_{noise}.csv\"\n",
    "    \n",
    "        # if os.path.exists(report_path):\n",
    "        #     # Nếu tồn tại thì merge vào file cũ\n",
    "        #     old_df = pd.read_csv(report_path)\n",
    "\n",
    "        #     print( old_df ) \n",
    "        #     print( report_df ) \n",
    "        #     merged_df = pd.merge(old_df, report_df, on='Model', how='inner')\n",
    "            \n",
    "        #     merged_df.to_csv(report_path, index=False)\n",
    "        # else:\n",
    "        #     # Tạo file mới\n",
    "        #     report_df.to_csv(report_path, index=False)\n",
    "\n",
    "# #Đường dẫn các file dữ liệu\n",
    "# baseline_file = \"~/GMM-nfst/Results/Baseline_noise73.csv\"\n",
    "# # model_files = {\n",
    "# #     \"data_BoTIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/5%_data_BoTIoT.csv_100k_oldlearn0.csv\",\n",
    "# #     \"data_CICIoT2023.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/5%_data_CICIoT2023.csv_100k_oldlearn0.csv\",\n",
    "# #     \"data_N_BaIoT.csv\" : \"~/GMM-nfst/Results/OURMODEL/SCALERS/5%_data_N_BaIoT.csv_100k_oldlearn0.csv\",\n",
    "# # }\n",
    "\n",
    "# model_files = {\n",
    "#     \"data_BoTIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_BoTIoT.csv0.csv\",\n",
    "#     \"data_CICIoT2023.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_CICIoT2023.csv0.csv\",\n",
    "#     \"data_N_BaIoT.csv\" : \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_N_BaIoT.csv0.csv\",\n",
    "#     \"data_ToNIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/73_old_data_ToNIoT.csv0.csv\"\n",
    "# }\n",
    "\n",
    "# # ['N_BaIoT_dataloader.csv', 'data_CICIoT2023.csv','data_BoTIoT.csv']\n",
    "# # Đọc dữ liệu baseline\n",
    "# baseline_df = pd.read_csv(baseline_file)\n",
    "\n",
    "# # Tìm giá trị AUC và AUCROC cao nhất trong baseline\n",
    "# baseline_results = {}\n",
    "# count = 0 \n",
    "\n",
    "# # scaler_names = ['MinMaxScaler','QuantileTransformer', 'StandardScaler','QuantileTransformer']\n",
    "# scaler_names = ['MinMaxScaler','Normalizer', 'StandardScaler','QuantileTransformer', 'RobustScaler' ]\n",
    "\n",
    "\n",
    "# for noise in [0, 1,3,5] : \n",
    "    \n",
    "#     baseline_noise = baseline_df[baseline_df[\"noise_percentage\"] == noise]\n",
    "#     baseline_noise = baseline_noise[baseline_noise['Model'] != 'LUNAR']\n",
    "    \n",
    "#     for dataset in model_files.keys():\n",
    "\n",
    "#         '''\n",
    "#         '''\n",
    "#         if ( dataset == \"data_BoTIoT.csv\" ): \n",
    "#             dataset_baseline_noise = baseline_noise[baseline_noise['scaled'] == 'QuantileTransformer']\n",
    "#         elif ( dataset == \"data_CICIoT2023.csv\" ) :\n",
    "#             dataset_baseline_noise = baseline_noise[baseline_noise['scaled'] == 'MinMaxScaler']\n",
    "#         else:\n",
    "#             dataset_baseline_noise = baseline_noise[baseline_noise['scaled'] == 'MinMaxScaler']\n",
    "        \n",
    "#         best_model = None\n",
    "#         best_loss = float('inf')\n",
    "#         for scaler in scaler_names: \n",
    "            \n",
    "#             dataset_baseline = dataset_baseline_noise[dataset_baseline_noise[\"Dataset\"] == dataset]\n",
    "#             max_auc = dataset_baseline[\"AUCPR\"]\n",
    "#             max_aucroc = dataset_baseline[\"AUCROC\"]\n",
    "#             model_name = dataset_baseline['Model'] \n",
    "\n",
    "\n",
    "#             selected_columns = dataset_baseline[['Model', 'AUCPR', 'AUCROC', 'scaled']]\n",
    "                             \n",
    "#             sorted_baseline = selected_columns.sort_values(by=['AUCROC'], ascending=[False])\n",
    "\n",
    "            \n",
    "#             model_df = pd.read_csv(model_files[dataset])\n",
    "#             model_noise = model_df[model_df[\"noise_percentage\"] == noise]\n",
    "#             model_scaler = model_noise[model_noise[\"scaler\"] == scaler] \n",
    "#             model_columns = model_scaler[['scaler', 'nCluster', 'AUCPR', 'AUCROC']]\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "#             for _, row in model_columns.iterrows():\n",
    "#                 if best_model is None or row['AUCROC'] > best_model['AUCROC']:\n",
    "#                     best_model = row\n",
    "            \n",
    "#         print( \"*\" * 50 , \"\\n\", best_loss ) \n",
    "#         if best_model is None:\n",
    "#             best_model = [\"ourmodel\", 0]  # Giá trị mặc định nếu không tìm thấy mô hình tốt nhất\n",
    "#         else:\n",
    "#             best_model = [\"ourmodel\"] + [best_model[3]] \n",
    "\n",
    "#         sorted_baseline = sorted_baseline[[\"Model\", \"AUCROC\"]] \n",
    "\n",
    "#         best_model_df = pd.DataFrame([best_model], columns = [\"Model\", \"AUCROC\"] )\n",
    "\n",
    "        \n",
    "#         report_df = pd.concat([best_model_df, sorted_baseline], ignore_index=True).fillna(0) \n",
    "#         # report_df.rename(columns={'AUCPR': dataset }, inplace=True)\n",
    "#         report_df.columns.values[1] = dataset \n",
    "#         report_path = f\"Results/final_report_noise_{noise}.csv\"\n",
    "    \n",
    "#         if os.path.exists(report_path):\n",
    "#             # Nếu tồn tại thì merge vào file cũ\n",
    "#             old_df = pd.read_csv(report_path)\n",
    "\n",
    "#             print( old_df ) \n",
    "#             print( report_df ) \n",
    "#             merged_df = pd.merge(old_df, report_df, on='Model', how='inner')\n",
    "            \n",
    "#             merged_df.to_csv(report_path, index=False)\n",
    "#         else:\n",
    "#             # Tạo file mới\n",
    "#             report_df.to_csv(report_path, index=False)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
