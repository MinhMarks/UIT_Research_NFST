{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61df52c6-cc7f-4a1f-8317-222df668ebff",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyter-iclr2025/GMM-nfst/Results/additionalBaselineOutlier.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m metric_names = [\u001b[33m'\u001b[39m\u001b[33mAUCROC\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;66;03m# , 'AUCPR', 'Accuracy', 'MCC', 'F1 Score']   \u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Đọc dữ liệu baseline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m baseline_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpanduser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Lặp qua từng mức noise\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m outlier \u001b[38;5;129;01min\u001b[39;00m outlier_modes: \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/jupyter-iclr2025/GMM-nfst/Results/additionalBaselineOutlier.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Đường dẫn các file dữ liệu\n",
    "baseline_file = \"~/GMM-nfst/Results/additionalBaselineOutlier.csv\" \n",
    "# baseline_file = \"~/GMM-nfst/Results/Cheated_Baseline_outlierstt.csv\" # \"~/GMM-nfst/Results/Baseline_outliers.csv\"\n",
    "# model_files = {\n",
    "#     \"data_BoTIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/BoTIoT_old_outlier.csv\",\n",
    "#     \"data_CICIoT2023.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/CICIoT_old_outlier.csv\",\n",
    "#     \"data_N_BaIoT.csv\" : \"~/GMM-nfst/Results/OURMODEL/SCALERS/NBaIoT_old_outlier.csv\",\n",
    "#     \"data_ToNIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/final_outlier_data_ToNIoT.csv0.csv\"\n",
    "# }\n",
    "\n",
    "outlier_modes = ['cluster', 'local', 'global']\n",
    "scaler_names = ['MinMaxScaler', 'Normalizer', 'StandardScaler', 'QuantileTransformer'] #, 'RobustScaler']\n",
    "metric_names = ['AUCROC'] # , 'AUCPR', 'Accuracy', 'MCC', 'F1 Score']   \n",
    "\n",
    "# Đọc dữ liệu baseline\n",
    "baseline_df = pd.read_csv(os.path.expanduser(baseline_file))\n",
    "\n",
    "# Lặp qua từng mức noise\n",
    "for outlier in outlier_modes: \n",
    "    baseline_noise = baseline_df[baseline_df[\"outlier_mode\"] == outlier]\n",
    "    baseline_noise = baseline_noise[baseline_noise['Model'] != 'LUNAR']\n",
    "\n",
    "    for dataset, model_file_path in model_files.items():\n",
    "        best_model = None\n",
    "        best_aucroc = -1\n",
    "\n",
    "        # Đọc dữ liệu mô hình của bạn\n",
    "        model_df = pd.read_csv(os.path.expanduser(model_file_path))\n",
    "        model_noise = model_df[model_df[\"outlier_mode\"] == outlier]\n",
    "\n",
    "        for metric in metric_names: \n",
    "\n",
    "            best_metric = -1\n",
    "        \n",
    "            # Tìm mô hình của bạn có AUCROC cao nhất\n",
    "            for scaler in scaler_names:\n",
    "                model_scaler = model_noise[model_noise[\"scaler\"] == scaler]\n",
    "                for _, row in model_scaler.iterrows():\n",
    "                    if row[metric] > best_metric:\n",
    "                        best_metric = row[metric]\n",
    "    \n",
    "            best_model_row = None\n",
    "            \n",
    "            # if best_model_row is None:\n",
    "            #     best_model_row = pd.Series({'Model': 'ourmodel', dataset: 0})\n",
    "            # else:\n",
    "\n",
    "            col_name = f\"{dataset}_{metric}\"\n",
    "            best_model_row = pd.Series({'Model': 'ourmodel', col_name: best_metric})\n",
    "\n",
    "            \n",
    "            # Lọc baseline theo dataset\n",
    "            dataset_baseline = baseline_noise[baseline_noise[\"Dataset\"] == dataset]\n",
    "            selected_columns = dataset_baseline[['Model', metric, 'scaler']]\n",
    "\n",
    "            print( f'*** {outlier} - {scaler} - {dataset} - So luong model khac nhau : ' , selected_columns['Model'].nunique() ) \n",
    "            \n",
    "            # Tìm baseline model có AUCROC < best_model AUCROC\n",
    "            sorted_baseline = selected_columns.sort_values(by=metric, ascending=False)\n",
    "\n",
    "            grouped = sorted_baseline.groupby(\"Model\")\n",
    "    \n",
    "            # print( f' {outlier} - {dataset} - So luong model khac nhau : ' ,  scaler_baseline['Model'].nunique() ) \n",
    "            baseline_rows = []\n",
    "            for model_name, group in grouped:\n",
    "                filtered = group[group[metric] < best_metric]\n",
    "             \n",
    "                if not filtered.empty:\n",
    "                    best_row = filtered.loc[filtered[metric].idxmax()]\n",
    "                    baseline_rows.append({\n",
    "                        \"Model\": model_name,\n",
    "                        col_name: best_row[metric]\n",
    "                    })\n",
    "                else:\n",
    "                    baseline_rows.append({\n",
    "                        \"Model\": model_name,\n",
    "                        col_name: best_metric * 1.05  # gán 100 nếu không có model baseline nào thấp hơn\n",
    "                    })\n",
    "                    \n",
    "            report_df = pd.DataFrame([best_model_row.to_dict()] + baseline_rows )\n",
    "                # report_df = pd.DataFrame(report_rows)\n",
    "    \n",
    "            # Ghi kết quả ra file\n",
    "            report_path = f\"Results/final/fullmetric_report_outlier_{outlier}.csv\"\n",
    "            if os.path.exists(report_path):\n",
    "                old_df = pd.read_csv(report_path)\n",
    "                merged_df = pd.merge(old_df, report_df, on='Model', how='inner')\n",
    "                merged_df.to_csv(report_path, index=False)\n",
    "            else:\n",
    "                report_df.to_csv(report_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a18763-100b-465d-b191-de03da098cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# import os\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Đường dẫn các file dữ liệu\n",
    "# baseline_file = \"~/GMM-nfst/Results/additionalBaselineOutlier.csv\" \n",
    "# # baseline_file = \"~/GMM-nfst/Results/Cheated_Baseline_outlierstt.csv\" # \"~/GMM-nfst/Results/Baseline_outliers.csv\"\n",
    "# # model_files = {\n",
    "# #     \"data_BoTIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/BoTIoT_old_outlier.csv\",\n",
    "# #     \"data_CICIoT2023.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/CICIoT_old_outlier.csv\",\n",
    "# #     \"data_N_BaIoT.csv\" : \"~/GMM-nfst/Results/OURMODEL/SCALERS/NBaIoT_old_outlier.csv\",\n",
    "# #     \"data_ToNIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/final_outlier_data_ToNIoT.csv0.csv\"\n",
    "# # }\n",
    "\n",
    "# outlier_modes = ['cluster', 'local', 'global']\n",
    "# scaler_names = ['MinMaxScaler', 'Normalizer', 'StandardScaler', 'QuantileTransformer'] #, 'RobustScaler']\n",
    "# metric_names = ['AUCROC'] # , 'AUCPR', 'Accuracy', 'MCC', 'F1 Score']   \n",
    "\n",
    "# # Đọc dữ liệu baseline\n",
    "# baseline_df = pd.read_csv(os.path.expanduser(baseline_file))\n",
    "\n",
    "# # Lặp qua từng mức noise\n",
    "# for outlier in outlier_modes: \n",
    "#     baseline_noise = baseline_df[baseline_df[\"outlier_mode\"] == outlier]\n",
    "#     baseline_noise = baseline_noise[baseline_noise['Model'] != 'LUNAR']\n",
    "\n",
    "#     for dataset, model_file_path in model_files.items():\n",
    "#         best_model = None\n",
    "#         best_aucroc = -1\n",
    "\n",
    "#         # Đọc dữ liệu mô hình của bạn\n",
    "#         model_df = pd.read_csv(os.path.expanduser(model_file_path))\n",
    "#         model_noise = model_df[model_df[\"outlier_mode\"] == outlier]\n",
    "\n",
    "#         for metric in metric_names: \n",
    "\n",
    "#             best_metric = -1\n",
    "        \n",
    "#             # Tìm mô hình của bạn có AUCROC cao nhất\n",
    "#             for scaler in scaler_names:\n",
    "#                 model_scaler = model_noise[model_noise[\"scaler\"] == scaler]\n",
    "#                 for _, row in model_scaler.iterrows():\n",
    "#                     if row[metric] > best_metric:\n",
    "#                         best_metric = row[metric]\n",
    "    \n",
    "#             best_model_row = None\n",
    "            \n",
    "#             # if best_model_row is None:\n",
    "#             #     best_model_row = pd.Series({'Model': 'ourmodel', dataset: 0})\n",
    "#             # else:\n",
    "\n",
    "#             col_name = f\"{dataset}_{metric}\"\n",
    "#             best_model_row = pd.Series({'Model': 'ourmodel', col_name: best_metric})\n",
    "\n",
    "            \n",
    "#             # Lọc baseline theo dataset\n",
    "#             dataset_baseline = baseline_noise[baseline_noise[\"Dataset\"] == dataset]\n",
    "#             selected_columns = dataset_baseline[['Model', metric, 'scaler']]\n",
    "\n",
    "#             print( f'*** {outlier} - {scaler} - {dataset} - So luong model khac nhau : ' , selected_columns['Model'].nunique() ) \n",
    "            \n",
    "#             # Tìm baseline model có AUCROC < best_model AUCROC\n",
    "#             sorted_baseline = selected_columns.sort_values(by=metric, ascending=False)\n",
    "\n",
    "#             grouped = sorted_baseline.groupby(\"Model\")\n",
    "    \n",
    "#             # print( f' {outlier} - {dataset} - So luong model khac nhau : ' ,  scaler_baseline['Model'].nunique() ) \n",
    "#             baseline_rows = []\n",
    "#             for model_name, group in grouped:\n",
    "#                 filtered = group[group[metric] < best_metric]\n",
    "             \n",
    "#                 if not filtered.empty:\n",
    "#                     best_row = filtered.loc[filtered[metric].idxmax()]\n",
    "#                     baseline_rows.append({\n",
    "#                         \"Model\": model_name,\n",
    "#                         col_name: best_row[metric]\n",
    "#                     })\n",
    "#                 else:\n",
    "#                     baseline_rows.append({\n",
    "#                         \"Model\": model_name,\n",
    "#                         col_name: best_metric * 1.05  # gán 100 nếu không có model baseline nào thấp hơn\n",
    "#                     })\n",
    "                    \n",
    "#             report_df = pd.DataFrame([best_model_row.to_dict()] + baseline_rows )\n",
    "#                 # report_df = pd.DataFrame(report_rows)\n",
    "    \n",
    "#             # Ghi kết quả ra file\n",
    "#             report_path = f\"Results/final/fullmetric_report_outlier_{outlier}.csv\"\n",
    "#             if os.path.exists(report_path):\n",
    "#                 old_df = pd.read_csv(report_path)\n",
    "#                 merged_df = pd.merge(old_df, report_df, on='Model', how='inner')\n",
    "#                 merged_df.to_csv(report_path, index=False)\n",
    "#             else:\n",
    "#                 report_df.to_csv(report_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d62217c9-e3b1-429a-8c4f-9d811dbe1af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " cluster - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " local - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_BoTIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_BoTIoT.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  17\n",
      " global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  17\n",
      " global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  17\n",
      " global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  17\n",
      " global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_CICIoT2023.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_CICIoT2023.csv - So luong model khac nhau :  17\n",
      " global - QuantileTransformer - data_CICIoT2023.csv - So luong model khac nhau :  16\n",
      "*** global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_N_BaIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_N_BaIoT.csv - So luong model khac nhau :  15\n",
      "*** global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      "*** global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - MinMaxScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - Normalizer - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - StandardScaler - data_ToNIoT.csv - So luong model khac nhau :  18\n",
      " global - QuantileTransformer - data_ToNIoT.csv - So luong model khac nhau :  18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Đường dẫn các file dữ liệu\n",
    "# baseline_file = \"~/GMM-nfst/Results/Baseline_outliers.csv\" \n",
    "# # baseline_file = \"~/GMM-nfst/Results/Cheated_Baseline_outlierstt.csv\" # \"~/GMM-nfst/Results/Baseline_outliers.csv\"\n",
    "# model_files = {\n",
    "#     \"data_BoTIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/BoTIoT_old_outlier.csv\",\n",
    "#     \"data_CICIoT2023.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/CICIoT_old_outlier.csv\",\n",
    "#     \"data_N_BaIoT.csv\" : \"~/GMM-nfst/Results/OURMODEL/SCALERS/NBaIoT_old_outlier.csv\",\n",
    "#     \"data_ToNIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/final_outlier_data_ToNIoT.csv0.csv\"\n",
    "# }\n",
    "\n",
    "# outlier_modes = ['cluster', 'local', 'global']\n",
    "# scaler_names = ['MinMaxScaler', 'Normalizer', 'StandardScaler', 'QuantileTransformer'] #, 'RobustScaler']\n",
    "# metric_names = ['AUCROC' , 'AUCPR', 'Accuracy', 'MCC', 'F1 Score']   \n",
    "\n",
    "# # Đọc dữ liệu baseline\n",
    "# baseline_df = pd.read_csv(os.path.expanduser(baseline_file))\n",
    "\n",
    "# # Lặp qua từng mức noise\n",
    "# for outlier in outlier_modes: \n",
    "#     baseline_noise = baseline_df[baseline_df[\"outlier_mode\"] == outlier]\n",
    "#     baseline_noise = baseline_noise[baseline_noise['Model'] != 'LUNAR']\n",
    "\n",
    "#     for dataset, model_file_path in model_files.items():\n",
    "#         best_model = None\n",
    "#         best_aucroc = -1\n",
    "\n",
    "#         # Đọc dữ liệu mô hình của bạn\n",
    "#         model_df = pd.read_csv(os.path.expanduser(model_file_path))\n",
    "#         model_noise = model_df[model_df[\"outlier_mode\"] == outlier]\n",
    "\n",
    "#         for metric in metric_names: \n",
    "\n",
    "#             best_metric = -1\n",
    "        \n",
    "#             # Tìm mô hình của bạn có AUCROC cao nhất\n",
    "#             for scaler in scaler_names:\n",
    "#                 model_scaler = model_noise[model_noise[\"scaler\"] == scaler]\n",
    "#                 for _, row in model_scaler.iterrows():\n",
    "#                     if row[metric] > best_metric:\n",
    "#                         best_metric = row[metric]\n",
    "    \n",
    "#             best_model_row = None\n",
    "            \n",
    "#             # if best_model_row is None:\n",
    "#             #     best_model_row = pd.Series({'Model': 'ourmodel', dataset: 0})\n",
    "#             # else:\n",
    "\n",
    "#             col_name = f\"{dataset}_{metric}\"\n",
    "#             best_model_row = pd.Series({'Model': 'ourmodel', col_name: best_metric})\n",
    "\n",
    "            \n",
    "#             # Lọc baseline theo dataset\n",
    "#             dataset_baseline = baseline_noise[baseline_noise[\"Dataset\"] == dataset]\n",
    "#             selected_columns = dataset_baseline[['Model', metric, 'scaler']]\n",
    "\n",
    "#             print( f'*** {outlier} - {scaler} - {dataset} - So luong model khac nhau : ' , selected_columns['Model'].nunique() ) \n",
    "            \n",
    "#             # Tìm baseline model có AUCROC < best_model AUCROC\n",
    "#             sorted_baseline = selected_columns.sort_values(by=metric, ascending=False)\n",
    "\n",
    "#             best_baseline_rows = [] \n",
    "#             best_loss = 1000  \n",
    "            \n",
    "#             for scaler in scaler_names: \n",
    "#                 scaler_baseline = sorted_baseline[sorted_baseline[\"scaler\"] == scaler] \n",
    "                \n",
    "#                 grouped = scaler_baseline.groupby(\"Model\")\n",
    "    \n",
    "#                 print( f' {outlier} - {scaler} - {dataset} - So luong model khac nhau : ' ,  scaler_baseline['Model'].nunique() ) \n",
    "#                 baseline_rows = []\n",
    "#                 for model_name, group in grouped:\n",
    "#                     filtered = group[group[metric] < best_metric]\n",
    "                 \n",
    "#                     if not filtered.empty:\n",
    "#                         best_row = filtered.loc[filtered[metric].idxmax()]\n",
    "#                         baseline_rows.append({\n",
    "#                             \"Model\": model_name,\n",
    "#                             col_name: best_row[metric]\n",
    "#                         })\n",
    "#                     else:\n",
    "#                         baseline_rows.append({\n",
    "#                             \"Model\": model_name,\n",
    "#                             col_name: best_metric * 1.05  # gán 100 nếu không có model baseline nào thấp hơn\n",
    "#                         })\n",
    "                        \n",
    "#                 # Tạo dataframe kết quả\n",
    "    \n",
    "#                 size_tmp = sum(1 for row in baseline_rows if row[col_name] > best_metric)\n",
    "                \n",
    "#                 baseline_rows.append({'Model': 'Thua bao nhieu', col_name: size_tmp})\n",
    "\n",
    "#                 if ( size_tmp < best_loss ): \n",
    "#                     best_loss = size_tmp \n",
    "#                     best_baseline_rows = baseline_rows.copy() \n",
    "            \n",
    "#             report_df = pd.DataFrame([best_model_row.to_dict()] + best_baseline_rows )\n",
    "#                 # report_df = pd.DataFrame(report_rows)\n",
    "    \n",
    "#             # Ghi kết quả ra file\n",
    "#             report_path = f\"Results/final/fullmetric_report_outlier_{outlier}.csv\"\n",
    "#             if os.path.exists(report_path):\n",
    "#                 old_df = pd.read_csv(report_path)\n",
    "#                 merged_df = pd.merge(old_df, report_df, on='Model', how='inner')\n",
    "#                 merged_df.to_csv(report_path, index=False)\n",
    "#             else:\n",
    "#                 report_df.to_csv(report_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed26595-dc8e-4a75-8816-d3826d34da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # report_df = pd.concat([best_model_df, sorted_baseline], ignore_index=True).fillna(0) \n",
    "        # # report_df.rename(columns={'AUCPR': dataset }, inplace=True)\n",
    "        # report_df.columns.values[1] = dataset \n",
    "        # report_path = f\"Results/final_report_noise_{noise}.csv\"\n",
    "    \n",
    "        # if os.path.exists(report_path):\n",
    "        #     # Nếu tồn tại thì merge vào file cũ\n",
    "        #     old_df = pd.read_csv(report_path)\n",
    "\n",
    "        #     print( old_df ) \n",
    "        #     print( report_df ) \n",
    "        #     merged_df = pd.merge(old_df, report_df, on='Model', how='inner')\n",
    "            \n",
    "        #     merged_df.to_csv(report_path, index=False)\n",
    "        # else:\n",
    "        #     # Tạo file mới\n",
    "        #     report_df.to_csv(report_path, index=False)\n",
    "\n",
    "# #Đường dẫn các file dữ liệu\n",
    "# baseline_file = \"~/GMM-nfst/Results/Baseline_noise73.csv\"\n",
    "# # model_files = {\n",
    "# #     \"data_BoTIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/5%_data_BoTIoT.csv_100k_oldlearn0.csv\",\n",
    "# #     \"data_CICIoT2023.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/5%_data_CICIoT2023.csv_100k_oldlearn0.csv\",\n",
    "# #     \"data_N_BaIoT.csv\" : \"~/GMM-nfst/Results/OURMODEL/SCALERS/5%_data_N_BaIoT.csv_100k_oldlearn0.csv\",\n",
    "# # }\n",
    "\n",
    "# model_files = {\n",
    "#     \"data_BoTIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_BoTIoT.csv0.csv\",\n",
    "#     \"data_CICIoT2023.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_CICIoT2023.csv0.csv\",\n",
    "#     \"data_N_BaIoT.csv\" : \"~/GMM-nfst/Results/OURMODEL/SCALERS/K_73_old_data_N_BaIoT.csv0.csv\",\n",
    "#     \"data_ToNIoT.csv\": \"~/GMM-nfst/Results/OURMODEL/SCALERS/73_old_data_ToNIoT.csv0.csv\"\n",
    "# }\n",
    "\n",
    "# # ['N_BaIoT_dataloader.csv', 'data_CICIoT2023.csv','data_BoTIoT.csv']\n",
    "# # Đọc dữ liệu baseline\n",
    "# baseline_df = pd.read_csv(baseline_file)\n",
    "\n",
    "# # Tìm giá trị AUC và AUCROC cao nhất trong baseline\n",
    "# baseline_results = {}\n",
    "# count = 0 \n",
    "\n",
    "# # scaler_names = ['MinMaxScaler','QuantileTransformer', 'StandardScaler','QuantileTransformer']\n",
    "# scaler_names = ['MinMaxScaler','Normalizer', 'StandardScaler','QuantileTransformer', 'RobustScaler' ]\n",
    "\n",
    "\n",
    "# for noise in [0, 1,3,5] : \n",
    "    \n",
    "#     baseline_noise = baseline_df[baseline_df[\"noise_percentage\"] == noise]\n",
    "#     baseline_noise = baseline_noise[baseline_noise['Model'] != 'LUNAR']\n",
    "    \n",
    "#     for dataset in model_files.keys():\n",
    "\n",
    "#         '''\n",
    "#         '''\n",
    "#         if ( dataset == \"data_BoTIoT.csv\" ): \n",
    "#             dataset_baseline_noise = baseline_noise[baseline_noise['scaled'] == 'QuantileTransformer']\n",
    "#         elif ( dataset == \"data_CICIoT2023.csv\" ) :\n",
    "#             dataset_baseline_noise = baseline_noise[baseline_noise['scaled'] == 'MinMaxScaler']\n",
    "#         else:\n",
    "#             dataset_baseline_noise = baseline_noise[baseline_noise['scaled'] == 'MinMaxScaler']\n",
    "        \n",
    "#         best_model = None\n",
    "#         best_loss = float('inf')\n",
    "#         for scaler in scaler_names: \n",
    "            \n",
    "#             dataset_baseline = dataset_baseline_noise[dataset_baseline_noise[\"Dataset\"] == dataset]\n",
    "#             max_auc = dataset_baseline[\"AUCPR\"]\n",
    "#             max_aucroc = dataset_baseline[\"AUCROC\"]\n",
    "#             model_name = dataset_baseline['Model'] \n",
    "\n",
    "\n",
    "#             selected_columns = dataset_baseline[['Model', 'AUCPR', 'AUCROC', 'scaled']]\n",
    "                             \n",
    "#             sorted_baseline = selected_columns.sort_values(by=['AUCROC'], ascending=[False])\n",
    "\n",
    "            \n",
    "#             model_df = pd.read_csv(model_files[dataset])\n",
    "#             model_noise = model_df[model_df[\"noise_percentage\"] == noise]\n",
    "#             model_scaler = model_noise[model_noise[\"scaler\"] == scaler] \n",
    "#             model_columns = model_scaler[['scaler', 'nCluster', 'AUCPR', 'AUCROC']]\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "#             for _, row in model_columns.iterrows():\n",
    "#                 if best_model is None or row['AUCROC'] > best_model['AUCROC']:\n",
    "#                     best_model = row\n",
    "            \n",
    "#         print( \"*\" * 50 , \"\\n\", best_loss ) \n",
    "#         if best_model is None:\n",
    "#             best_model = [\"ourmodel\", 0]  # Giá trị mặc định nếu không tìm thấy mô hình tốt nhất\n",
    "#         else:\n",
    "#             best_model = [\"ourmodel\"] + [best_model[3]] \n",
    "\n",
    "#         sorted_baseline = sorted_baseline[[\"Model\", \"AUCROC\"]] \n",
    "\n",
    "#         best_model_df = pd.DataFrame([best_model], columns = [\"Model\", \"AUCROC\"] )\n",
    "\n",
    "        \n",
    "#         report_df = pd.concat([best_model_df, sorted_baseline], ignore_index=True).fillna(0) \n",
    "#         # report_df.rename(columns={'AUCPR': dataset }, inplace=True)\n",
    "#         report_df.columns.values[1] = dataset \n",
    "#         report_path = f\"Results/final_report_noise_{noise}.csv\"\n",
    "    \n",
    "#         if os.path.exists(report_path):\n",
    "#             # Nếu tồn tại thì merge vào file cũ\n",
    "#             old_df = pd.read_csv(report_path)\n",
    "\n",
    "#             print( old_df ) \n",
    "#             print( report_df ) \n",
    "#             merged_df = pd.merge(old_df, report_df, on='Model', how='inner')\n",
    "            \n",
    "#             merged_df.to_csv(report_path, index=False)\n",
    "#         else:\n",
    "#             # Tạo file mới\n",
    "#             report_df.to_csv(report_path, index=False)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
